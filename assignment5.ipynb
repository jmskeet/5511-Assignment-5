{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00fc08d",
   "metadata": {},
   "source": [
    "# Assignment 5 - General Adversariel Network (GAN) Monet Painting Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a73e40",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This project is a GAN based style transformation. The goal of this project is to develop a GAN model that can accurately transfer the Monet style of paintings to a photograph. The model will train on sample Monet painting images learning the Monet style.  It will then reproduce photographs in the Monet style. The data is provided by  the Kaggle competition 'I'm Somewhat of a Painter Myself' Competition and located at https://www.kaggle.com/competitions/gan-getting-started.\n",
    "\n",
    "\n",
    "CycleGAN a very popular extension of the GAN architecture will be used to develope the model.  CycleGan deploys two Generator and discriminator models to create the style transfer paramters.  \n",
    "\n",
    "Describe CycleGan\n",
    "\n",
    "describe  generative deep learning models\n",
    "\n",
    "Generative AI is a type of AI that uses deep learning techniques to generate new content, such as images, music, and text.\n",
    "\n",
    "Given that the course material was a very brief, high level review of GAN theory and did not cover implementation of GAN models, this project will rely heavily on the tutorials in the references for implementation guidance.  Custom adaptations will be injected where possible to build a unique project structured around the tutorials base structures.  The course did not offer specifics into the CycleGAN package\n",
    "\n",
    "## Data Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd15d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc401d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set Page Width to 100%\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6217c9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Load Required Resources\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7823c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Data\n",
    "# The .tfrec files from the Kaggle Competition site will be used\n",
    "\n",
    "monet_file_id = tf.io.gfile.glob(str('gan-getting-started/monet_tfrec/*.tfrec'))\n",
    "\n",
    "photo_file_id = tf.io.gfile.glob(str('gan-getting-started/photo_tfrec/*.tfrec'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec8a1a",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc73d6",
   "metadata": {},
   "source": [
    "EDA will be performed as follows:\n",
    "\n",
    "    1. Verify Train Image Counts and Size\n",
    "    2. Verify Test Image Counts and size\n",
    "    3. Provide Sample Monet and photograh images\n",
    "\n",
    "Various images were reviewed and the Monet images are assessed to be of the Monet style.  Given that the images are directly from the cmpetion data set no addtional EDA is requied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5672811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample Images and sizes\n",
    "monet_file_id_df = pd.DataFrame(monet_file_id)\n",
    "print('Monet File Summary:')\n",
    "print(monet_file_id_df.head())\n",
    "print(monet_file_id_df.info())\n",
    "\n",
    "photo_file_id_df = pd.DataFrame(monet_file_id)\n",
    "print('Photo FileSummary:')\n",
    "print(monet_file_id_df.head())\n",
    "print(monet_file_id_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e469076",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Example Images\n",
    "\n",
    "monet1 = Image.imread('data/gan-getting-started/monet_jpg/0a5075d42a.jpg')\n",
    "print('Monet Sample Image 1 Shape')\n",
    "print(monet1.shape)\n",
    "plt.imshow(monet1)\n",
    "plt.title('Monet Sample Image 1')\n",
    "plt.show()\n",
    "\n",
    "monet2 = Image.imread('data/gan-getting-started/monet_jpg/0bd913dbc7.jpg')\n",
    "print('Monet Sample Image 2 Shape')\n",
    "print(monet2.shape)\n",
    "plt.imshow(monet2)\n",
    "plt.title('Monet Sample Image 2')\n",
    "plt.show()\n",
    "\n",
    "photo1 = Image.imread('data/gan-getting-started/photo_jpg/0a0c3a6d07.jpg')\n",
    "print('Photo Sample Image 1 Shape')\n",
    "print(photo1.shape)\n",
    "plt.imshow(photo1)\n",
    "plt.title('Photo Sample Image 1')\n",
    "plt.show()\n",
    "\n",
    "photo2 = Image.imread('data/gan-getting-started/photo_jpg/0a0d3e6ea7.jpg')\n",
    "print('Photo Sample Image 2 Shape')\n",
    "print(photo2.shape)\n",
    "plt.imshow(photo2)\n",
    "plt.title('Photo Sample Image 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33726680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Suppress Warning Messages Code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a175bf0a",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "Model Architecture\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7058e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Split the training data\n",
    "x_training_set, x_validation_set, target_train, target_validation= train_test_split(train_df['text'].values, train_df['target'].values, random_state=25, test_size=0.3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c88361",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use this format for upsampleand down sample instaed od the def upsample/downsample from tutorial\n",
    "Monet who???\n",
    "def make_generator_model():   \n",
    "    # Reshaping the images\n",
    "    inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "    \n",
    "    # Encoder\n",
    "    down1 = tf.keras.layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu')(inputs)\n",
    "    down2 = tf.keras.layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu')(down1)\n",
    "    down3 = tf.keras.layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu')(down2)\n",
    "    \n",
    "    # Decoder\n",
    "    up1 = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu')(down3)\n",
    "    up2 = tf.keras.layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu')(up1)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2DTranspose(3, (4, 4), strides=2, padding='same', activation='tanh')(up2)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103ab01",
   "metadata": {},
   "source": [
    "### Photo Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ee5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Before and after images of photos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2bf67",
   "metadata": {},
   "source": [
    "**Disuss Images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a699bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sumbit Results\n",
    "import PIL\n",
    "! mkdir ../images\n",
    "\n",
    "i = 1\n",
    "for img in photo_df:\n",
    "    prediction = monet_generator(img, training=False)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    im = PIL.Image.fromarray(prediction)\n",
    "    im.save(\"../images/\" + str(i) + \".jpg\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get test set predictions\n",
    "target_test = model.predict(sequence_x_test_set_padded, verbose = 1)\n",
    "target_test\n",
    "print('Test Shape: ', target_test.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480061f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate submission file\n",
    "#Kaggle CycleGan Monet tutorial submission code was adpated to the specifics of this project\n",
    "\n",
    "test_submission = np.where(target_test <= 0.5, 0, 1)\n",
    "\n",
    "final_submission = np.transpose(test_submission)[0]\n",
    "final_submission = pd.DataFrame()\n",
    "final_submission['id'] = test_df['id']\n",
    "final_submission['target'] = test_submission\n",
    "print(final_submission.head())\n",
    "\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")\n",
    "\n",
    "'/kaggle/working/images.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59effa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle Tutorial\n",
    "\n",
    "# The CycleGAN class has been imported from the Kaggle Tutorial notebook\n",
    "# link: https://www.kaggle.com/code/amyjang/monet-cyclegan-tutorial/notebook#Build-the-generator\n",
    "\n",
    "class CycleGan(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        monet_generator,\n",
    "        photo_generator,\n",
    "        monet_discriminator,\n",
    "        photo_discriminator,\n",
    "        lambda_cycle=10,\n",
    "    ):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.m_gen = monet_generator\n",
    "        self.p_gen = photo_generator\n",
    "        self.m_disc = monet_discriminator\n",
    "        self.p_disc = photo_discriminator\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        m_gen_optimizer,\n",
    "        p_gen_optimizer,\n",
    "        m_disc_optimizer,\n",
    "        p_disc_optimizer,\n",
    "        gen_loss_fn,\n",
    "        disc_loss_fn,\n",
    "        cycle_loss_fn,\n",
    "        identity_loss_fn\n",
    "    ):\n",
    "        super(CycleGan, self).compile()\n",
    "        self.m_gen_optimizer = m_gen_optimizer\n",
    "        self.p_gen_optimizer = p_gen_optimizer\n",
    "        self.m_disc_optimizer = m_disc_optimizer\n",
    "        self.p_disc_optimizer = p_disc_optimizer\n",
    "        self.gen_loss_fn = gen_loss_fn\n",
    "        self.disc_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = cycle_loss_fn\n",
    "        self.identity_loss_fn = identity_loss_fn\n",
    "        \n",
    "    def train_step(self, batch_data):\n",
    "        real_monet, real_photo = batch_data\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # photo to monet back to photo\n",
    "            fake_monet = self.m_gen(real_photo, training=True)\n",
    "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
    "\n",
    "            # monet to photo back to monet\n",
    "            fake_photo = self.p_gen(real_monet, training=True)\n",
    "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
    "\n",
    "            # generating itself\n",
    "            same_monet = self.m_gen(real_monet, training=True)\n",
    "            same_photo = self.p_gen(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing real images\n",
    "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
    "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing fake images\n",
    "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
    "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
    "\n",
    "            # evaluates generator loss\n",
    "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
    "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
    "\n",
    "            # evaluates total cycle consistency loss\n",
    "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
    "\n",
    "            # evaluates total generator loss\n",
    "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
    "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
    "\n",
    "            # evaluates discriminator loss\n",
    "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
    "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
    "\n",
    "        # Calculate the gradients for generator and discriminator\n",
    "        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n",
    "                                                  self.m_gen.trainable_variables)\n",
    "        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n",
    "                                                  self.p_gen.trainable_variables)\n",
    "\n",
    "        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n",
    "                                                      self.m_disc.trainable_variables)\n",
    "        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n",
    "                                                      self.p_disc.trainable_variables)\n",
    "\n",
    "        # Apply the gradients to the optimizer\n",
    "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n",
    "                                                 self.m_gen.trainable_variables))\n",
    "\n",
    "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n",
    "                                                 self.p_gen.trainable_variables))\n",
    "\n",
    "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n",
    "                                                  self.m_disc.trainable_variables))\n",
    "\n",
    "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n",
    "                                                  self.p_disc.trainable_variables))\n",
    "        \n",
    "        return {\n",
    "            \"monet_gen_loss\": total_monet_gen_loss,\n",
    "            \"photo_gen_loss\": total_photo_gen_loss,\n",
    "            \"monet_disc_loss\": monet_disc_loss,\n",
    "            \"photo_disc_loss\": photo_disc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca285084",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3196ba",
   "metadata": {},
   "source": [
    "**Image Comparison**\n",
    "\n",
    "\n",
    "\n",
    "**Dicussion**\n",
    "\n",
    "\n",
    "\n",
    "**Submission**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb41f5",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "GAN â€” CycleGAN (Playing magic with pictures), https://jonathan-hui.medium.com/gan-cyclegan-6a50e7600d7\n",
    "\n",
    "Monet CycleGAN Tutorial, https://www.kaggle.com/code/amyjang/monet-cyclegan-tutorial\n",
    "\n",
    "Train your first CycleGAN for Image to Image Translation, https://blog.jaysinha.me/train-your-first-cyclegan-for-image-to-image-translation/\n",
    "\n",
    "Overview of CycleGAN architecture and training, https://towardsdatascience.com/overview-of-cyclegan-architecture-and-training-afee31612a2f#:~:text=A%20CycleGAN%20is%20composed%20of,other%20transform%20zebras%20into%20horses.\n",
    "\n",
    "Tensorflow CycleGan, https://www.tensorflow.org/tutorials/generative/cyclegan\n",
    "\n",
    "A hands-on guide to TFRecords, https://towardsdatascience.com/a-practical-guide-to-tfrecords-584536bc786c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ce110",
   "metadata": {},
   "source": [
    "### Kaggle Code Refernces\n",
    "CycleGAN Monet, https://www.kaggle.com/code/anubhav012/cyclegan-monet\n",
    "\n",
    "Monet Who?, https://www.kaggle.com/code/nisargbhatt/monet-who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d06cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
